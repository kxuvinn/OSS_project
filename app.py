from flask import Flask, render_template, request, jsonify
import torch
import cv2
import numpy as np
import sys
from pathlib import Path

app = Flask(__name__)

# yolov5 ë¡œì»¬ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).resolve().parent / 'yolov5'))

# yolov5 ë‚´ë¶€ ëª¨ë“ˆ import
from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.augmentations import letterbox

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = 'cpu' 
model = torch.jit.load('model/korean.pt', map_location=device)
model.eval()

model.names = [
    'giyeok', 'nieun', 'digeut', 'rieul', 'mieum', 'bieup', 'siot', 'ieung',
    'jieut', 'chieut', 'kieuk', 'tieut', 'pieup', 'hieut',
    'a', 'ya', 'eo', 'yeo', 'o', 'yo', 'u', 'yu', 'eu', 'i',
    'ae', 'yae', 'e', 'ye', 'oe', 'wi', 'ui'
]

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/quiz/korean')
def quiz_korean():
    return render_template('quiz_korean.html')

@app.route('/predict', methods=['POST'])
def predict():
    file = request.files['image']
    target = request.form.get('target')

    # ì˜ì–´ â†’ í•œê¸€ ë¼ë²¨ ë§¤í•‘
    label_map = {
        'giyeok': 'ã„±', 'nieun': 'ã„´', 'digeut': 'ã„·', 'rieul': 'ã„¹',
        'mieum': 'ã…', 'bieup': 'ã…‚', 'siot': 'ã……', 'ieung': 'ã…‡',
        'jieut': 'ã…ˆ', 'chieut': 'ã…Š', 'kieuk': 'ã…‹', 'tieut': 'ã…Œ',
        'pieup': 'ã…', 'hieut': 'ã…', 'a': 'ã…', 'ya': 'ã…‘',
        'eo': 'ã…“', 'yeo': 'ã…•', 'o': 'ã…—', 'yo': 'ã…›',
        'u': 'ã…œ', 'yu': 'ã… ', 'eu': 'ã…¡', 'i': 'ã…£',
        'ae': 'ã…', 'yae': 'ã…’', 'e': 'ã…”', 'ye': 'ã…–',
        'oe': 'ã…š', 'wi': 'ã…Ÿ', 'ui': 'ã…¢',
    }

    # ì´ë¯¸ì§€ ë””ì½”ë”©
    img0 = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)

    # í•´ìƒë„ë¥¼ 640x640ìœ¼ë¡œ resize
    img0 = cv2.resize(img0, (640, 640))

    # ì „ì²˜ë¦¬: BGR â†’ RGB, HWC â†’ CHW
    img = img0[:, :, ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    img = torch.from_numpy(img).to(device).float() / 255.0
    if img.ndimension() == 3:
        img = img.unsqueeze(0)

    # ì˜ˆì¸¡
    pred = model(img)
    pred = non_max_suppression(pred, conf_thres=0.1)[0]

    if pred is not None and len(pred):
        pred = pred.cpu()
        box = max(pred, key=lambda x: x[4])
        cls_id = int(box[5].item())
        conf = float(box[4].item())
        eng_label = model.names[cls_id]
        label = label_map.get(eng_label, 'unknown')
        is_correct = (label == target)
        
        print("âœ… ëª¨ë¸ í´ë˜ìŠ¤ ëª©ë¡:", model.names)
        print("ğŸ“‚ model.names:", model.names)
        print("ğŸ“¦ pred tensor:", pred)
        print("ğŸ” ì˜ˆì¸¡ í´ë˜ìŠ¤:", eng_label)
        print("ğŸ“Œ confidence:", conf)
        print("ğŸ¯ target:", target)
        print("âœ… ë§¤ì¹­ ê²°ê³¼:", is_correct)
        print("ğŸ–¼ï¸ ì…ë ¥ ì´ë¯¸ì§€ shape:", img.shape)
        print("ğŸ“¸ max pixel:", img.max().item(), "min pixel:", img.min().item())
        
    else:
        label = 'none'
        conf = 0.0
        is_correct = False

    return jsonify({
        'prediction': label,
        'confidence': round(conf, 3),
        'is_correct': is_correct,
        'target': target
    })

if __name__ == '__main__':
    app.run(debug=True)
