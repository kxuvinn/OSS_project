# 🔍SignQUIZ: 청각장애인의 수화 언어 학습 도구 개발
## 프로젝트 배경
- 수화 언어의 교육 부족으로 수어로 소통하는 청각장애인들이 어려움을 겪고 있다.
- 청각장애인 약 44만명 중 수어를 일상어로 사용하는 청각장애인은 약 5만 2000여명으로 추정된다. 농인 학생들을 위한 농학교조차 입말로 수업이 이루어지고 교과 과목에 수어가 없는 경우가 대부분이다. 즉, 현재 수어 교육 인프라가 매우 미흡하다는 사실이다.
- 따라서 이러한 사회적 문제를 해결하기 위하여 청각장애인들이 수업 외에도 학습자 스스로가 올바른 수형인지를 판단할 수 있도록 자기주도학습이 가능하게 해야 한다. 이를 해소하기 위하여 카메라를 이용한 수어 학습 보조 시스템이 그 대안이 될 수 있다.

<br>

## 프로젝트 목적
- 청각장애인을 위한 손 모양 기반 수화 언어 학습 도구 개발
    본 프로젝트는 한글(자음/ 모음)과 숫자로 구성된 수화 언어를 손의 모양(비디오 신호)만으로 인식하고 학습할 수 있도록 지원하는 도구를 개발하는 것을 목적으로 한다. 수화를 처음 배우는 아동 및 청각장애인 학습자가 재미있고 직관적으로 수화를 익힐 수 있도록 게임 형식의 학습 환경을 제공한다.
- AI 기반의 실시간 수화 인식 모델
    손의 모양을 카메라로 촬영하고 이를 YOLO 기반 딥러닝 모델로 인식하여, 학습자가 표현한 수화를 실시간으로 분석하고 정답과 오답을 확인할 수 있는 피드백을 제공할 수 있는 기술을 개발한다.
  #### 사회적 효과
  - 본 도구를 통해 언제 어디서나 반복적으로 수화를 연습할 수 있어 청각장애 아동의 언어 접근성이 향상된다.
  - 게임 기반 학습을 통해 비장애인 아동이나 일반인도 수화에 흥미를 느끼고 배울 수 있어, 사회 전반의 수화 사용률 증가와 인식 개선에 기여한다.
  - 지역이나 경제적 제약을 뛰어넘는 학습 기회를 제공하며 포용적 사회 구현을 위한 기반 기술로 활용이 가능하다.

<br>

## 프로젝트 설명
### 💡오픈 소스 모델: YOLOv5

#### 1. 데이터셋 구성
- 수화 이미지 데이터 (한글 자음과 모음 + 숫자)
- train 70%, valid 20%, test 10%

#### 2. 학습 환경
- Google Colab, Anaconda
- Epoch: 100, 300, 350, 400 총 4회 실시 (숫자 데이터셋으로 100, 250 2회 실시)
- Batch Size: 64
- Image size: 640 x 640
- 평가 지표: mAP@0.5, mAP@0.5:0.95

#### 3. 학습 명령어

본 프로젝트의 YOLOv5 학습(한글 데이터 바탕) 은 Google Colab 환경에서 `.ipynb` 노트북을 통해 실행하였다.

YOLOv5 모델 학습(숫자 데이터 바탕)은 아나콘다에서 아래 명령어 실행하였다.

```bash
python train.py --img 640 --batch 64 --epochs 300 \
--data /data.yaml --weights yolov5s.pt --name HangulSignModel
```
### 오픈소스 기술과 연동
 본 프로젝트의 UI는 웹 브라우저에서 수어 퀴즈를 실시간으로 수행할 수 있도록 설계되었으며, 사용자 제스처 입력부터 예측 및 피드백까지 자동화되었다. 프론트엔드와 백엔드는 REST API 기반 비동기 통신으로 연결되며, 실시간 처리와 모델 경량화, 전처리 자동화 등이 통합된 형태로 구현되었다.

- 서버 시작 시, torch.jit.load()를 사용하여 사전 학습된 YOLOv5 모델 두 종류(korea.pt, number.pt)를 불러온다.
- 모델은 서버 환경에서 안정적으로 실행될 수 있도록 TorchScript 형식으로 export 되었으며, model.eval() 상태로 추론 전용 모드로 전환한다.
- 각각 .names 속성을 통해 클래스 인덱스와 실제 라벨(예: ＇giyeok＇ -> ‘ㄱ’)을 매핑한다.

### UI 구성
- 사용자가 메인 화면에 접속하여 퀴즈를 선택하면 index.html이 렌더링되며, ‘한글’ 또는 ‘숫자’ 버튼 클릭 시 각각 /quiz/korean, /quiz/number 경로로 이동하고, 사용자 선택에 따라 문제 유형을 분기하는 라우팅 알고리즘의 역할 수행한다.
- 각 퀴즈 화면은 웹캠 실시간 스트리밍 영상 video와 문제 div id="target"을 동적으로 출력하고, JavaScript가 페이지 로드 시 문제 리스트 중 하나를 무작위로 선택하고, 현재 문제를 currentTarget 변수에 저장된다.
- 서버로부터 반환된 JSON 응답에는 예측 클래스, confidence 점수, 정답 여부가 포함된다. JavaScript는 위 값을 기반으로 현재 문제와 예측값이 일치하는지를 판단하고, video 요소의 테두리 색상을 초록 또는 빨강으로 동적으로 변경한다.

<br>

## 프로젝트 결과


## 파일별 설명 요약

### signquiz

- **frontend/**  
  - `templates/` : 프로젝트 메인 페이지, 퀴즈 화면   
  - `static/js/` : JavaScript 코드 (문제 제시, 웹캠 예측 처리 등)  
  - `static/css/` : 퀴즈 페이지용 CSS 스타일 시트

- **backend/**  
  - `app.py` : Flask 서버 실행 파일
  - `model/` : 한글 수어 인식용 모델, 숫자 수어 인식용 모델  
  - `yolov5/` : YOLOv5 추론 관련 내부 모듈 폴더

- **requirements.txt**  
  Python 패키지 의존성 목록

---

### yolov5_hangul

- 한글 수어 인식 모델을 학습하기 위한 YOLOv5 학습 코드
- `train.py`, `data.yaml`, `runs/` 등 학습 스크립트 및 결과 파일 포함

---

### yolov5_numbersign

- 숫자 수어 인식 모델을 학습하기 위한 YOLOv5 학습 코드
- `train.py`, `data.yaml`, `runs/` 등 숫자 기반 학습 구성 포함

<br>

## 설치 및 사용 방법

### 1. signquiz 폴더 다운로드

이 프로젝트를 실행하려면 `signquiz/` 폴더만 필요

1. 저장소 상단의 `Code` 버튼을 클릭한 후 `Download ZIP` 선택  
2. 압축을 해제한 뒤, `signquiz/` 폴더만 꺼내서 사용

---

### 2. Python 환경 준비

Python 3.8 이상이 설치되어 있다면 바로 실행 가능
가상환경은 필수는 아니지만, 패키지 충돌을 방지하고 싶다면 사용하는 것을 권장

#### (선택 사항) conda 가상환경 사용 방법

```bash
# 가상환경 생성
conda create -n (가상환경 이름) python=3.8

# 가상환경 활성화
conda activate (가상환경 이름)
```

> 가상환경을 사용하지 않더라도, Python이 설치되어 있다면 전역 환경에서도 실행 가능

---

### 3. 의존성 설치

`signquiz/` 폴더 내에서 아래 명령어 실행

```bash
pip install -r requirements.txt
```

---

### 4. 백엔드 서버 실행

다음 명령어를 통해 Flask 서버 실행

```bash
cd signquiz/backend
python app.py
```

실행 후 브라우저에서 아래 주소로 접속하여 서비스 이용 가능:

```
http://127.0.0.1:5000/
```

<br>

## 🛠 사용한 기술 및 도구

| 분류 | 도구 / 기술 | 설명 |
|------|--------------|------|
| **데이터 라벨링** | **Roboflow** | 이미지 기반 수어 데이터에 바운딩 박스 또는 라벨을 쉽게 지정할 수 있는 웹 라벨링 툴로, YOLO 포맷으로 자동 변환 가능 |
| **프로그래밍 언어** | **Python, JavaScript, HTML, CSS** | Python은 백엔드 서버 및 AI 모델 구동에 사용되었고, JavaScript/HTML/CSS는 웹 프론트엔드 구축 및 사용자 인터랙션 구현에 사용 |
| **웹 프레임워크** | **Flask** | Python 기반의 경량 웹 프레임워크로, REST API 제공, HTML 템플릿 렌더링, 웹캠 이미지 처리 기능 구현에 활용 |
| **딥러닝 프레임워크** | **PyTorch, TorchScript** | PyTorch는 YOLO 기반 모델 학습 및 추론에 사용되었으며, TorchScript를 통해 모델을 직렬화하여 실행 속도를 향상시킴 |
| **모델 학습 환경** | **Google Colab, Anaconda** | Google Colab은 GPU 자원을 활용한 모델 학습에 사용되었고, Anaconda는 로컬 개발 및 테스트용 Python 가상 환경 설정에 활용됨 |
| **웹캠 연동** | **JavaScript API (`getUserMedia`)** | 사용자의 웹 브라우저에서 웹캠을 호출하여 실시간 영상 스트리밍을 처리함 |
| **개발 환경** | **Anaconda (로컬 테스트)**<br>**Flask 내장 개발 서버 (서버 실행)** | 개발 초기 단계에서는 Anaconda를 통한 로컬 테스트 환경을 사용하고, 최종 서버는 Flask의 내장 서버를 통해 구동함 |

<br>

## 참여한 팀원

👑 **이채연 (팀장)**  
- 수화 데이터셋 생성: 손 동작을 촬영하여 한글 수어(자음/모음) 및 숫자 수어(1~10)에 대한 이미지 데이터셋을 생성

- 한글/숫자 모델 학습: GPU 리소스를 활용하기 위해 Google Colab에서 PyTorch 기반 YOLO 모델을 사용하여 한글 및 숫자 수어 데이터를 학습시킴. 성능 향상을 위해 에포크 수를 조절하며 여러 번 반복 학습을 수행

- 프로그램 최종 평가: 학습된 모델을 아나콘다 환경에서 로딩하여 실시간 웹캠과 연동하고 사용자 수어 동작을 인식한 뒤 예측 결과를 시각적으로 피드백. 최종 프로그램 실행을 통해 모델의 정확도, 응답 속도, 사용자 인터페이스 등을 종합적으로 검토

- 최종 보고서 정리: 팀원들로부터 받은 내용을 바탕으로 전체 보고서를 통일된 형식과 흐름으로 정리하고, 중복되거나 누락된 내용을 조정하여 최종 결과물로 통합함. 문장 표현 및 기술적 설명의 일관성을 유지하도록 내용 편집

---

🧠 **김수빈**  
- 수화 데이터셋 생성 및 라벨링:  손 동작을 촬영하여 한글 수어(자음/모음) 및 숫자 수어(1~10)에 대한 이미지 데이터셋을 생성하고 Roboflow를 활용해 한글(자음/모음) 데이터셋 라벨링.  YOLO 학습에 최적화된 포맷으로 데이터를 가공하여 모델 학습에 사용할 수 있도록 정제

- AI 모델 연동: YOLOv5로 학습된 모델을 TorchScript 형식으로 변환하여 Flask 서버에 적재 가능하도록 최적화. TorchScript 모델을 활용해 추론 속도를 향상시키고 서버에서 실시간 예측이 가능하도록 구성

- 백엔드: Flask 프레임 워크를 기반으로 웹 서버를 구축하고 프론트엔드로부터 웹캠 이미지 데이터를 수신하여 모델에 전달, 예측 결과를 JSON 형태로 변환하는 전체 흐름 구현. 비동기 통신이 가능한 API 구조를 설계하여 프론트엔드와 실시간으로 상호작용하며 예측된 결과가 현재 퀴즈 문제와 일치하는지 판단하고 정오답 여부를 즉시 반환하는 기능 구현

---

💻 **장세미**  
- 수화 데이터셋 생성 및 라벨링:  손 동작을 촬영하여 한글 수어(자음/모음) 및 숫자 수어(1~10)에 대한 이미지 데이터셋을 생성하고 Roboflow를 활용해 숫자(1~10) 데이터셋 라벨링. YOLO 학습에 최적화된 포맷으로 데이터를 가공하여 모델 학습에 사용할 수 있도록 정제

- 한글/숫자 모델 정확도 검사: 학습된 best.pt 모델 파일을 활용하여 Google Colab에서 성능평가를 수행. 테스트셋을 통해 클래스별 정확도 및 mAP 값을 확인하고, 학습 에포크 수에 따른 성능 차이를 비교 분석

- 프론트엔드: 사용자 인터페이스를 구성하여 퀴즈 유형 선택 화면과 수어 퀴즈 실행 화면을 설계하고 구현. 웹캠을 통해 촬영된 실시간 영상에 대해 서버로 예측 요청을 보내고 서버로부터 수신된 예측 결과에 따라 정답 여부를 판단하여 영상 테두리를 초록색 또는 빨간색으로 표시하는 피드백 기능 구현

<br>

## 참고 자료

참고 GitHub: [bleuuue/Signal 프로젝트](https://github.com/bleuuue/Signal)

<br>

## 라이선스

본 프로젝트는 [LICENSE.txt](./LICENSE.txt)를 따릅니다. 
